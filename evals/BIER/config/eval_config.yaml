# BIER Evaluation Configuration

# GraphRAG Pipeline Settings
retrieval:
  embedding_model: "BAAI/bge-small-en-v1.5"
  milvus_profile: "production"
  collection_name: "bier_hotpotqa_chunks" 
  enable_reranking: true
  reranker_config:
    model_name: "cross-encoder/ms-marco-MiniLM-L-6-v2"
    batch_size: 32

# BEIR Evaluation Settings
evaluation:
  # Datasets to evaluate on
  datasets:
    # Quick evaluation datasets (smaller, faster)
    quick:
      - "nfcorpus"      # Natural Language Processing papers
      - "fiqa"          # Financial question answering
      - "scifact"       # Scientific fact verification
    
    # Standard evaluation suite  
    standard:
      - "msmarco"       # Web search
      - "trec-covid"    # COVID-19 literature
      - "nfcorpus"      # NLP papers
      - "nq"            # Natural Questions
      - "fiqa"          # Financial QA
      - "arguana"       # Argument search
      - "scifact"       # Scientific facts
      - "scidocs"       # Scientific document search
    
    # Full evaluation suite
    full:
      - "msmarco"
      - "trec-covid" 
      - "nfcorpus"
      - "nq"
      - "hotpotqa"
      - "fiqa"
      - "arguana"
      - "touche-2020"
      - "cqadupstack"
      - "quora"
      - "dbpedia-entity"
      - "scidocs"
      - "fever"
      - "climate-fever"
      - "scifact"

  # Evaluation metrics
  metrics:
    - "ndcg"          # Normalized Discounted Cumulative Gain
    - "map"           # Mean Average Precision
    - "recall"        # Recall
    - "precision"     # Precision
  
  # Top-k values for evaluation
  top_k_values:
    - 1
    - 3
    - 5
    - 10
    - 100

  # Evaluation settings
  batch_size: 100
  ignore_identical_ids: true
  score_function: "dot"

# Output Settings
output:
  save_individual_results: true
  save_summary: true
  save_per_query_results: false  # Set to true for detailed analysis
  
  # Output formats
  formats:
    - "json"
    - "csv"

# Logging Settings
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/bier_evaluation.log"

# Resource Management
resources:
  # Memory management for large datasets
  max_memory_gb: 16
  
  # Parallel processing
  max_workers: 4
  
  # Caching
  enable_caching: true
  cache_dir: "cache/"